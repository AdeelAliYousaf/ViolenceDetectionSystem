{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdeelAliYousaf/ViolenceDetectionSystem/blob/main/ViolenceDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "v1UgJm8XascX",
        "outputId": "fe25afee-2e99-410c-8002-456fcc5dc27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Pre-trained model loaded successfully.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b07b6d0ce4fe629236.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b07b6d0ce4fe629236.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip uninstall tensorflow keras\n",
        "!pip install tensorflow==2.15 keras==2.15 skimage gradio\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from keras.models import load_model\n",
        "import time\n",
        "import gradio as gr\n",
        "\n",
        "model_path = \"ViolenceDetectionModel.keras\"\n",
        "model = load_model(model_path, compile=False)\n",
        "print(\"[INFO] Pre-trained model loaded successfully.\")\n",
        "\n",
        "def load_video_frames(path, max_frames=30, target_size=(160, 160)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "\n",
        "    while len(frames) < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = resize(frame, target_size, preserve_range=True).astype(np.float32) / 255.0\n",
        "        frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    while len(frames) < max_frames:\n",
        "        frames.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.float32))\n",
        "\n",
        "    return np.array(frames)\n",
        "\n",
        "def predict_violence(video_path, threshold=0.65):\n",
        "    frames = load_video_frames(video_path)\n",
        "    frames = np.expand_dims(frames, axis=0)\n",
        "    start = time.time()\n",
        "    preds = model.predict(frames)[0]\n",
        "    end = time.time()\n",
        "\n",
        "    print(f\"[INFO] Prediction took {end - start:.2f}s\")\n",
        "    print(f\"[INFO] Predicted probabilities: {preds}\")\n",
        "\n",
        "    is_violent = preds[1] >= threshold\n",
        "    print(f\"[RESULT] Violence detected: {is_violent} (Confidence: {preds[1]:.4f})\")\n",
        "\n",
        "    return is_violent, preds[1]\n",
        "\n",
        "def gradio_predict(video_file):\n",
        "    is_fight, confidence = predict_violence(video_file)\n",
        "    result_text = f\"ðŸ”´ Violence Detected! (Confidence: {confidence:.2f})\" if is_fight else f\"ðŸŸ¢ No Violence Detected. (Confidence: {confidence:.2f})\"\n",
        "    return result_text\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŽ¥ Violence Detection in Video\")\n",
        "    gr.Markdown(\"Upload a video and click 'Detect Violence'. The model will analyze the clip and display the result.\")\n",
        "\n",
        "    video_input = gr.Video(label=\"Upload a short video\")\n",
        "    output_text = gr.Textbox(label=\"Prediction Result\", interactive=False)\n",
        "    predict_button = gr.Button(\"ðŸš¨ Detect Violence\")\n",
        "\n",
        "    predict_button.click(fn=gradio_predict, inputs=video_input, outputs=output_text)\n",
        "\n",
        "demo.launch(debug=False, share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1n3BDdNnMde_Db3Gz5ll7WlibNZt1msda",
      "authorship_tag": "ABX9TyMC4IYDtCK8+EfqXSqdXrSb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
